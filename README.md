# NaturalLanguageProcessing

Dataset used: Twitter codemix data.
1. Language Modelling:
Calculated Trigram, Bigram, Unigram perplexities on codemix data.

2. CMI vs Perplexity.
Calculated CMI for each tweet and seperated tweets into 10 sets based on the CMI values.
For each set we found perplexity.
